{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDet:\n",
    "    def __init__(self, detection_score=0.6):\n",
    "        ### Init model\n",
    "        self.__setup_model()\n",
    "        self.detection_score = detection_score\n",
    "        self.area_focus = {'start': (250,420), 'end':(450,520)}\n",
    "\n",
    "        ### Config\n",
    "        self.is_draw = True\n",
    "        self.class_dict = {0:'person', 1:'phone'}\n",
    "        self.class_color_dict = {0:(255, 0, 0), \n",
    "                                 1:(0, 0, 255),\n",
    "                                 'area_normal':(0,128,128),\n",
    "                                 'area_alert':(0,165,255)\n",
    "                                 }\n",
    "\n",
    "    def __setup_model(self):\n",
    "        model_path = os.path.join('../weight/cctv-feed-ml_v2_yolov8l.pt')\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def __bb_intersection_over_person(self, box_focus, box_person):\n",
    "        # determine the (x, y)-coordinates of the intersection rectangle\n",
    "        xA = max(box_focus[0], box_person[0])\n",
    "        yA = max(box_focus[1], box_person[1])\n",
    "        xB = min(box_focus[2], box_person[2])\n",
    "        yB = min(box_focus[3], box_person[3])\n",
    "\n",
    "        # compute the area of intersection rectangle\n",
    "        intersec_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "        # rectangles\n",
    "        box_focus_area = (box_focus[2] - box_focus[0] + 1) * (box_focus[3] - box_focus[1] + 1)\n",
    "        box_person_area = (box_person[2] - box_person[0] + 1) * (box_person[3] - box_person[1] + 1)\n",
    "\n",
    "        iop = intersec_area / box_person_area #float(boxAArea + boxBArea - interArea) ### iop = intersec over person\n",
    "\n",
    "        return iop\n",
    "\n",
    "\n",
    "    def inference(self, img):\n",
    "        alert_focus_area = False\n",
    "\n",
    "        result = self.model(img, verbose=False)\n",
    "\n",
    "        cls = result[0].boxes.cls.cpu().numpy()    # cls, (N, 1)\n",
    "        probs = result[0].boxes.conf.cpu().numpy()  # confidence score, (N, 1)\n",
    "        boxes = result[0].boxes.xyxy.cpu().numpy()   # box with xyxy format, (N, 4)\n",
    "\n",
    "        lab_arr = []\n",
    "        \n",
    "        if self.is_draw:\n",
    "            # print(cls,probs)\n",
    "            for clas, prob, box in zip(cls, probs, boxes):\n",
    "                if prob >= self.detection_score:\n",
    "\n",
    "                    (x, y, x2, y2) = box\n",
    "\n",
    "                    # print(clas, int(x), int(y), int(x2), int(y2))\n",
    "                    lab_arr.append([clas, int(x), int(y), int(x2), int(y2)])\n",
    "\n",
    "                    # cal iop - intersec over person\n",
    "                    iop = self.__bb_intersection_over_person(box_focus = list(self.area_focus['start']) + list(self.area_focus['end']), # [x1,y1,x2,y2]\n",
    "                                                             box_person = [x,y,x2,y2])\n",
    "                    if iop >= 0.1:\n",
    "                        alert_focus_area = True\n",
    "\n",
    "\n",
    "                    # Draw rec\n",
    "                    cv2.rectangle(img, (int(x), int(y)), (int(x2), int(y2)), self.class_color_dict[clas], 2) ## class\n",
    "                    cv2.rectangle(img, self.area_focus['start'], self.area_focus['end'], color=self.class_color_dict['area_normal'], thickness=2) #(x1,y1),(x2,y2)\n",
    "\n",
    "\n",
    "                    # Get size txt\n",
    "                    draw_txt = self.class_dict[clas] + \": \" + str(round(prob*100,1)) +\"%\"\n",
    "                    (w, h), _ = cv2.getTextSize(\n",
    "                            draw_txt, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "\n",
    "                    # Prints the text.    \n",
    "                    cv2.rectangle(img, (int(x), int(y) - 20), (int(x) + w, int(y)), self.class_color_dict[clas], -1)\n",
    "                    cv2.putText(img, draw_txt, (int(x), int(y) - 5),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
    "                    \n",
    "                    ### show counting frame\n",
    "                    # cv2.putText(img, '1', (int(20), int(30)),\n",
    "                    #                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
    "\n",
    "                    \n",
    "                    # cv2.putText(img, str(clas) + '_' + str(round(prob,3)), (int(x), int(y)-10), cv2.FONT_HERSHEY_SIMPLEX, 1, self.class_color_dict[clas], 2)  # Text in red color\n",
    "\n",
    "        return img, alert_focus_area, lab_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD = ObjectDet(detection_score=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [01:08<00:00,  1.65it/s]\n",
      "100%|██████████| 150/150 [01:52<00:00,  1.33it/s]\n",
      "100%|██████████| 149/149 [01:52<00:00,  1.33it/s]\n",
      "100%|██████████| 135/135 [01:53<00:00,  1.19it/s]\n",
      "100%|██████████| 100/100 [01:11<00:00,  1.40it/s]\n",
      "100%|██████████| 95/95 [01:10<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "### edit this ###\n",
    "class_map = {\n",
    "            0.0: 'person',\n",
    "            1.0: 'phone',\n",
    "            # Add more class mappings as needed\n",
    "        }\n",
    "\n",
    "folder_root = '../../cctv-feed-outside-room/test-image/UAT_inspect'\n",
    "folder_list = ['KBF','KTF','LPF','PLF','PTF','SRF']\n",
    "### edit this ###\n",
    "\n",
    "\n",
    "for focus_folder in folder_list:\n",
    "    src_drt = f'{folder_root}/{focus_folder}/'\n",
    "    files_list = os.listdir(src_drt) \n",
    "\n",
    "\n",
    "    files_name = [filename for filename in files_list if filename.endswith('.jpg')]\n",
    "    for img_name in tqdm(files_name):\n",
    "        img = cv2.imread(src_drt + img_name, cv2.IMREAD_COLOR)\n",
    "        image_height, image_width, channels = img.shape\n",
    "\n",
    "        det,alert_focus_area,lab_arr = OD.inference(img)\n",
    "\n",
    "        labelme_annotations = []\n",
    "        file_name = img_name.split('.')[0]\n",
    "\n",
    "        for yolo_label in lab_arr:\n",
    "            clas, x_top_left, y_top_left, x_bottom_right, y_bottom_right = yolo_label\n",
    "\n",
    "            labelme_annotation = {\n",
    "                    \"label\": class_map[clas],  # Replace with actual class name\n",
    "                    \"points\": [[x_top_left, y_top_left], [x_bottom_right, y_bottom_right]],\n",
    "                    \"description\": \"\",\n",
    "                    \"shape_type\": \"rectangle\"\n",
    "                }\n",
    "\n",
    "            labelme_annotations.append(labelme_annotation)\n",
    "\n",
    "\n",
    "        json_file_full = {\n",
    "            \"version\": \"5.3.0a0\",\n",
    "            \"flags\": {},\n",
    "            \"shapes\" : labelme_annotations,\n",
    "            \"imagePath\": file_name + '.jpg',\n",
    "            \"imageData\" : None\n",
    "        }\n",
    "\n",
    "\n",
    "        # print(json_file_full)\n",
    "\n",
    "        with open(src_drt + file_name + \".json\", \"w\") as json_file:\n",
    "            json.dump(json_file_full, json_file)\n",
    "\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
