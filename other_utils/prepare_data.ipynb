{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Recheck bdbox [Optional Just check bdbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "### you must edit Config\n",
    "# class_dict = {0:\"person\",1:\"phone\"}, person_with_phone\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(image_path, yolo_file, save_path):\n",
    "\n",
    "    class_dict = {0:\"person\",1:\"phone\"}\n",
    "    # class_dict = {0:\"car\"}\n",
    "    class_color = {0:(255,0,0) ,1:(0,0,255)}\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Read the YOLO format file\n",
    "    with open(yolo_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    \n",
    "    for line in lines:\n",
    "        # Parse the line to extract bounding box information\n",
    "        class_label, x, y, width, height = map(float, line.split())\n",
    "\n",
    "        # Convert normalized coordinates to pixel values\n",
    "        x_min = int((x - width / 2) * image_width)\n",
    "        y_min = int((y - height / 2) * image_height)\n",
    "        x_max = int((x + width / 2) * image_width)\n",
    "        y_max = int((y + height / 2) * image_height)\n",
    "\n",
    "        # Draw bounding box rectangle on the image\n",
    "        # label = f\"{class_label}\"\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), class_color[class_label], 2)\n",
    "\n",
    "        # Add label text near the bounding box\n",
    "        cv2.putText(image, class_dict[class_label], (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, class_color[class_label], 2)\n",
    "\n",
    "        \n",
    "    # save_path = os.path.join(\"person-phone\",\"post-prd-12-2023\",\"post-prd-batch-12-2023\", \"imgs_view\", file_name+\".jpg\")\n",
    "    # save_path = os.path.join(\"person-phone\", \"UAT\", \"test_person-phone-allcase\", \"imgs_view\", file_name+\".jpg\")\n",
    "    cv2.imwrite(save_path, image)\n",
    "        \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NKA-ch8_1</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NKA-ch8_2</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NKA-ch8_3</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NKA-ch8_4</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NKA-ch8_6</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NKA-ch8_7</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NKA-ch8_8</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NKA-ch8_9</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NKA-ch8_22</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NKA-ch8_25</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NKA-ch8_26</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NKA-ch8_27</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NKA-ch8_28</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NKA-ch8_29</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NKA-ch8_30</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NKA-ch8_34</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NKA-ch8_35</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NKA-ch8_36</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NKA-ch8_39</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NKA-ch8_40</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NKA-ch8_41</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NKA-ch8_42</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NKA-ch8_43</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NKA-ch8_44</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NKA-ch8_45</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NKA-ch8_46</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NKA-ch8_47</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NKA-ch8_48</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NKA-ch8_49</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NKA-ch8_50</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NKA-ch8_59</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NKA-ch8_64</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NKA-ch8_76</td>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_path video_num cls\n",
       "0    NKA-ch8_1   NKA-ch8   1\n",
       "1    NKA-ch8_2   NKA-ch8   2\n",
       "2    NKA-ch8_3   NKA-ch8   3\n",
       "3    NKA-ch8_4   NKA-ch8   4\n",
       "4    NKA-ch8_6   NKA-ch8   6\n",
       "5    NKA-ch8_7   NKA-ch8   7\n",
       "6    NKA-ch8_8   NKA-ch8   8\n",
       "7    NKA-ch8_9   NKA-ch8   9\n",
       "8   NKA-ch8_22   NKA-ch8  22\n",
       "9   NKA-ch8_25   NKA-ch8  25\n",
       "10  NKA-ch8_26   NKA-ch8  26\n",
       "11  NKA-ch8_27   NKA-ch8  27\n",
       "12  NKA-ch8_28   NKA-ch8  28\n",
       "13  NKA-ch8_29   NKA-ch8  29\n",
       "14  NKA-ch8_30   NKA-ch8  30\n",
       "15  NKA-ch8_34   NKA-ch8  34\n",
       "16  NKA-ch8_35   NKA-ch8  35\n",
       "17  NKA-ch8_36   NKA-ch8  36\n",
       "18  NKA-ch8_39   NKA-ch8  39\n",
       "19  NKA-ch8_40   NKA-ch8  40\n",
       "20  NKA-ch8_41   NKA-ch8  41\n",
       "21  NKA-ch8_42   NKA-ch8  42\n",
       "22  NKA-ch8_43   NKA-ch8  43\n",
       "23  NKA-ch8_44   NKA-ch8  44\n",
       "24  NKA-ch8_45   NKA-ch8  45\n",
       "25  NKA-ch8_46   NKA-ch8  46\n",
       "26  NKA-ch8_47   NKA-ch8  47\n",
       "27  NKA-ch8_48   NKA-ch8  48\n",
       "28  NKA-ch8_49   NKA-ch8  49\n",
       "29  NKA-ch8_50   NKA-ch8  50\n",
       "30  NKA-ch8_59   NKA-ch8  59\n",
       "31  NKA-ch8_64   NKA-ch8  64\n",
       "32  NKA-ch8_76   NKA-ch8  76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### you must edit Config\n",
    "# file_path = os.listdir('./datasets/person_phon/combine-dataset-batch1-2_v1_1000x750/train/images')\n",
    "# file_path = os.listdir('./person-phone/UAT/test_person-phone-allcase/images')\n",
    "# file_path = os.listdir('./person-phone/post-prd-12-2023/post-prd-batch-12-2023/images')\n",
    "focus_site = \"NKA\"\n",
    "\n",
    "file_path = os.listdir(f\"../assets/crop-img/{focus_site}/images/\")\n",
    "# file_path = os.listdir(\"../person-phone/post-prd-02-2024/all/select_data_test_032024/images/\")\n",
    "df = pd.DataFrame(file_path,columns=['file_path'])\n",
    "\n",
    "new = df['file_path'].str.split('.jpg',expand = True)\n",
    "df['file_path'] = new[0]\n",
    "new = df['file_path'].str.split('_',expand = True)\n",
    "df['video_num'] = new[0]\n",
    "df['cls'] = new[1]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NKA-ch8</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_num  count\n",
       "0   NKA-ch8     33"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.video_num.value_counts()\n",
    "df.video_num.value_counts().reset_index()#['index'].str.split('-', n=1,expand = True)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:05<00:00,  5.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "### you must edit Config\n",
    "# image_path = os.path.join(\"datasets\",\"person_phone\",\"combine-dataset-batch1-2_v1_fullsize\",\"train\",\"images\",file_name+\".jpg\")\n",
    "# yolo_path =  os.path.join(\"datasets\",\"person_phone\",\"combine-dataset-batch1-2_v1_fullsize\",\"train\",\"labels\",file_name+\".txt\")\n",
    "\n",
    "df_sample = df\n",
    "image_arr = []\n",
    "\n",
    "\n",
    "\n",
    "for file_name in tqdm(df_sample['file_path'].tolist()):\n",
    "\n",
    "    image_path = os.path.join(\"..\",\"assets\",\"crop-img\", focus_site, \"images\", file_name+\".jpg\")\n",
    "    yolo_path =  os.path.join(\"..\",\"assets\",\"crop-img\", focus_site, \"labels\", file_name+\".txt\")\n",
    "    save_path = os.path.join(\"..\",\"assets\",\"crop-img\", focus_site, \"imgs_view\", file_name+\".jpg\")\n",
    "\n",
    "    draw_bounding_boxes(image_path, yolo_path, save_path)\n",
    "\n",
    "\n",
    "    # image_arr.append(draw_bounding_boxes(image_path, yolo_path, file_name))\n",
    "    \n",
    "# img_arr_show(image_arr,df_sample['file_path'].tolist(),is_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(image_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2_no-phone_ (1)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1-2_no-phone_ (10)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1-2_no-phone_ (11)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1-2_no-phone_ (12)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1-2_no-phone_ (13)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>8_no-phone_ (7)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>8_no-phone_ (8)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>8_no-phone_ (9)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9_none_ (1)</td>\n",
       "      <td>9</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>9_none_ (4)</td>\n",
       "      <td>9</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_path video_num       cls\n",
       "0     1-1-2_no-phone_ (1)     1-1-2  no-phone\n",
       "1    1-1-2_no-phone_ (10)     1-1-2  no-phone\n",
       "2    1-1-2_no-phone_ (11)     1-1-2  no-phone\n",
       "3    1-1-2_no-phone_ (12)     1-1-2  no-phone\n",
       "4    1-1-2_no-phone_ (13)     1-1-2  no-phone\n",
       "..                    ...       ...       ...\n",
       "292       8_no-phone_ (7)         8  no-phone\n",
       "293       8_no-phone_ (8)         8  no-phone\n",
       "294       8_no-phone_ (9)         8  no-phone\n",
       "295           9_none_ (1)         9      none\n",
       "296           9_none_ (4)         9      none\n",
       "\n",
       "[297 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.listdir('datasets/combine-dataset-batch1-2_v1/train/images')\n",
    "df = pd.DataFrame(file_path,columns=['file_path'])\n",
    "\n",
    "new = df['file_path'].str.split('.',expand = True)\n",
    "df['file_path'] = new[0]\n",
    "new = df['file_path'].str.split('_',expand = True)\n",
    "df['video_num'] = new[0]\n",
    "df['cls'] = new[1]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1-1-2</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>none</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>none</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>none</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2-1-2</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-1-2</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4-1-3</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>no-phone</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>none</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_path\n",
       "video_num cls                \n",
       "1-1-2     no-phone         14\n",
       "          phone            48\n",
       "10        none              3\n",
       "11        none              2\n",
       "12        none              2\n",
       "2-1-2     no-phone         26\n",
       "          phone             8\n",
       "3-1-2     no-phone         42\n",
       "4-1-3     no-phone         12\n",
       "          phone            27\n",
       "6         no-phone         24\n",
       "          phone            17\n",
       "7         no-phone         13\n",
       "          none              1\n",
       "          phone            23\n",
       "8         no-phone         33\n",
       "9         none              2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=[\"video_num\",\"cls\"]).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust train val test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(os.path.join(\"datasets\",video_test), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Config this #######\n",
    "video_test = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2_no-phone_ (1)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1-2_no-phone_ (10)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1-2_no-phone_ (11)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1-2_no-phone_ (12)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1-2_no-phone_ (13)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>8_no-phone_ (7)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>8_no-phone_ (8)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>8_no-phone_ (9)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9_none_ (1)</td>\n",
       "      <td>9</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>9_none_ (4)</td>\n",
       "      <td>9</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_path video_num       cls   type\n",
       "0     1-1-2_no-phone_ (1)     1-1-2  no-phone  train\n",
       "1    1-1-2_no-phone_ (10)     1-1-2  no-phone  train\n",
       "2    1-1-2_no-phone_ (11)     1-1-2  no-phone  train\n",
       "3    1-1-2_no-phone_ (12)     1-1-2  no-phone  train\n",
       "4    1-1-2_no-phone_ (13)     1-1-2  no-phone  train\n",
       "..                    ...       ...       ...    ...\n",
       "292       8_no-phone_ (7)         8  no-phone  train\n",
       "293       8_no-phone_ (8)         8  no-phone  train\n",
       "294       8_no-phone_ (9)         8  no-phone  train\n",
       "295           9_none_ (1)         9      none  train\n",
       "296           9_none_ (4)         9      none  train\n",
       "\n",
       "[297 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'] = 'train'\n",
    "df.loc[df['video_num'] == video_test, 'type'] = 'test'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['type']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df[df['type']=='train'], test_size=.2, stratify =df[df['type']=='train']['cls'])\n",
    "df_val['type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no-phone    112\n",
       "phone        84\n",
       "none          8\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.cls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no-phone    28\n",
       "phone       22\n",
       "none         2\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.cls.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no-phone    24\n",
       "phone       17\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.cls.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-1-2_no-phone_ (28)</td>\n",
       "      <td>3-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8_no-phone_ (20)</td>\n",
       "      <td>8</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1-2_phone_ (42)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_none_ (1)</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-1-2_no-phone_ (1)</td>\n",
       "      <td>3-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>6_phone_ (5)</td>\n",
       "      <td>6</td>\n",
       "      <td>phone</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>6_phone_ (6)</td>\n",
       "      <td>6</td>\n",
       "      <td>phone</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>6_phone_ (7)</td>\n",
       "      <td>6</td>\n",
       "      <td>phone</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6_phone_ (8)</td>\n",
       "      <td>6</td>\n",
       "      <td>phone</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6_phone_ (9)</td>\n",
       "      <td>6</td>\n",
       "      <td>phone</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_path video_num       cls   type\n",
       "0    3-1-2_no-phone_ (28)     3-1-2  no-phone  train\n",
       "1        8_no-phone_ (20)         8  no-phone  train\n",
       "2       1-1-2_phone_ (42)     1-1-2     phone  train\n",
       "3            10_none_ (1)        10      none  train\n",
       "4     3-1-2_no-phone_ (1)     3-1-2  no-phone  train\n",
       "..                    ...       ...       ...    ...\n",
       "292          6_phone_ (5)         6     phone   test\n",
       "293          6_phone_ (6)         6     phone   test\n",
       "294          6_phone_ (7)         6     phone   test\n",
       "295          6_phone_ (8)         6     phone   test\n",
       "296          6_phone_ (9)         6     phone   test\n",
       "\n",
       "[297 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merge dataset\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat([df_train, df_val, df_test], axis=0).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    68.686869\n",
      "val      17.508418\n",
      "test     13.804714\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((df.type.value_counts()/df.type.value_counts().sum())*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AXON\\\\CCTV\\\\workspace\\\\prepare_data'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(\"datasets\",video_test))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"train\"))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"train\",'images'))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"train\",'labels'))\n",
    "\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"test\"))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"test\",'images'))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"test\",'labels'))\n",
    "\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"val\"))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"val\",'images'))\n",
    "os.mkdir(os.path.join(\"datasets\",video_test,\"val\",'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree(os.path.join(\"datasets\",video_test), ignore_errors=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "for file_name, typ in zip(df['file_path'].tolist(),df['type'].tolist()):\n",
    "    \n",
    "    image_path = os.path.join(\"datasets\",\"combine-dataset-batch1-2_v1\",\"train\",\"images\",file_name+\".jpg\")\n",
    "    yolo_path =  os.path.join(\"datasets\",\"combine-dataset-batch1-2_v1\",\"train\",\"labels\",file_name+\".txt\")\n",
    "\n",
    "\n",
    "    shutil.copy(image_path, os.path.join(\"datasets\",video_test,typ,\"images\",file_name+\".jpg\"))\n",
    "    shutil.copy(yolo_path, os.path.join(\"datasets\",video_test,typ,\"labels\",file_name+\".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val by Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.111  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "Setup complete  (20 CPUs, 31.7 GB RAM, 106.8/150.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\AXON\\\\CCTV\\\\workspace\\\\prepare_data'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# model = YOLO('../../assets/weights/K-fold_mix_batch1-2_v1/4-1-3/weights/best.pt')\n",
    "model = YOLO('../../assets/weights/k-fold_d2_adj2_L_150/1-1-2/weights/best.pt')\n",
    "# model = YOLO('../../assets/weights/K-fold_d2_adj2_L_150/kfold_1-1-2_d2-adj2_L_150/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.111  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 268 layers, 43608150 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\6\\test\\labels... 41 images, 0 backgrounds, 0 corrupt: 100%|██████████| 41/41 [00:00<00:00, 2273.58it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\6\\test\\labels.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:16<00:00,  5.59s/it]\n",
      "                   all         41         65      0.369        0.5      0.393      0.305\n",
      "                person         41         48      0.738          1      0.787      0.609\n",
      "     person_with_phone         41         17          0          0          0          0\n",
      "Speed: 0.7ms preprocess, 395.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val21\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=\"../../workspace/prepare_data/data.yaml\", conf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.box.map50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.box.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.box.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.box.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels_in_folder(file_path_list):\n",
    "    label_count = {}\n",
    "    for file_name in file_path_list:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            # file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_name, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    label = line.split()[0]\n",
    "                    if label in label_count:\n",
    "                        label_count[label] += 1\n",
    "                    else:\n",
    "                        label_count[label] = 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>video_num</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1-2_no-phone_ (1)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1-2_no-phone_ (10)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-1-2_no-phone_ (11)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-1-2_no-phone_ (12)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-1-2_no-phone_ (13)</td>\n",
       "      <td>1-1-2</td>\n",
       "      <td>no-phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>BKF-CREAM-2_phone_ (95)</td>\n",
       "      <td>BKF-CREAM-2</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>BKF-CREAM-2_phone_ (96)</td>\n",
       "      <td>BKF-CREAM-2</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>BKF-CREAM-2_phone_ (97)</td>\n",
       "      <td>BKF-CREAM-2</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>BKF-CREAM-2_phone_ (98)</td>\n",
       "      <td>BKF-CREAM-2</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>BKF-CREAM-2_phone_ (99)</td>\n",
       "      <td>BKF-CREAM-2</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_path    video_num       cls\n",
       "0         1-1-2_no-phone_ (1)        1-1-2  no-phone\n",
       "1        1-1-2_no-phone_ (10)        1-1-2  no-phone\n",
       "2        1-1-2_no-phone_ (11)        1-1-2  no-phone\n",
       "3        1-1-2_no-phone_ (12)        1-1-2  no-phone\n",
       "4        1-1-2_no-phone_ (13)        1-1-2  no-phone\n",
       "...                       ...          ...       ...\n",
       "1503  BKF-CREAM-2_phone_ (95)  BKF-CREAM-2     phone\n",
       "1504  BKF-CREAM-2_phone_ (96)  BKF-CREAM-2     phone\n",
       "1505  BKF-CREAM-2_phone_ (97)  BKF-CREAM-2     phone\n",
       "1506  BKF-CREAM-2_phone_ (98)  BKF-CREAM-2     phone\n",
       "1507  BKF-CREAM-2_phone_ (99)  BKF-CREAM-2     phone\n",
       "\n",
       "[1508 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# CCTV\\workspace\\prepare_data\\datasets\\person_phone\\combine-dataset-batch1-2_v1_1000x750\\train\\images\n",
    "\n",
    "file_path = os.listdir('./person-personwithphone/images')\n",
    "df = pd.DataFrame(file_path,columns=['file_path'])\n",
    "\n",
    "new = df['file_path'].str.split('.',expand = True)\n",
    "df['file_path'] = new[0]\n",
    "new = df['file_path'].str.split('_',expand = True)\n",
    "df['video_num'] = new[0]\n",
    "df['cls'] = new[1]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 587, '1': 1019}\n"
     ]
    }
   ],
   "source": [
    "yolo_path_arr = []\n",
    "\n",
    "# for file_name in df[df['video_num']=='7']['file_path'].tolist():\n",
    "for file_name in df['file_path'].tolist():\n",
    "\n",
    "    # image_path = os.path.join(\"datasets\",\"train\",\"images\",file_name+\".jpg\")\n",
    "    yolo_path =  os.path.join(\"person-personwithphone\",\"labels\",file_name+\".txt\")\n",
    "    yolo_path_arr.append(yolo_path)\n",
    "    # image_arr.append(draw_bounding_boxes(image_path, yolo_path))\n",
    "# yolo_path_arr\n",
    "print(count_labels_in_folder(yolo_path_arr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('../../assets/weights/K-fold_d2_adj2_L_600/4-1-3/weights/best.pt')\n",
    "# model = YOLO('../../assets/weights/K-fold_d2_adj2_L_150/kfold_2-1-2_d2-adj2_L_150/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (1).jpg: 480x640 5 persons, 511.9ms\n",
      "Speed: 2.5ms preprocess, 511.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (10).jpg: 480x640 3 persons, 522.0ms\n",
      "Speed: 2.0ms preprocess, 522.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (11).jpg: 480x640 3 persons, 526.2ms\n",
      "Speed: 2.9ms preprocess, 526.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (12).jpg: 480x640 3 persons, 540.7ms\n",
      "Speed: 2.0ms preprocess, 540.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (2).jpg: 480x640 4 persons, 530.7ms\n",
      "Speed: 1.0ms preprocess, 530.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (3).jpg: 480x640 3 persons, 511.2ms\n",
      "Speed: 2.1ms preprocess, 511.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (4).jpg: 480x640 2 persons, 510.5ms\n",
      "Speed: 1.9ms preprocess, 510.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (5).jpg: 480x640 2 persons, 527.1ms\n",
      "Speed: 1.9ms preprocess, 527.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (6).jpg: 480x640 2 persons, 517.4ms\n",
      "Speed: 3.0ms preprocess, 517.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (7).jpg: 480x640 3 persons, 498.2ms\n",
      "Speed: 2.0ms preprocess, 498.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (8).jpg: 480x640 3 persons, 508.9ms\n",
      "Speed: 2.0ms preprocess, 508.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_no-phone_ (9).jpg: 480x640 2 persons, 509.5ms\n",
      "Speed: 2.0ms preprocess, 509.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (1).jpg: 480x640 2 persons, 510.7ms\n",
      "Speed: 2.0ms preprocess, 510.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (10).jpg: 480x640 3 persons, 519.1ms\n",
      "Speed: 1.9ms preprocess, 519.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (11).jpg: 480x640 3 persons, 525.0ms\n",
      "Speed: 2.0ms preprocess, 525.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (12).jpg: 480x640 3 persons, 527.3ms\n",
      "Speed: 1.9ms preprocess, 527.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (13).jpg: 480x640 3 persons, 544.0ms\n",
      "Speed: 3.6ms preprocess, 544.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (14).jpg: 480x640 3 persons, 532.9ms\n",
      "Speed: 2.0ms preprocess, 532.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (15).jpg: 480x640 3 persons, 525.4ms\n",
      "Speed: 1.0ms preprocess, 525.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (16).jpg: 480x640 3 persons, 536.4ms\n",
      "Speed: 1.9ms preprocess, 536.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (17).jpg: 480x640 3 persons, 552.7ms\n",
      "Speed: 2.0ms preprocess, 552.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (18).jpg: 480x640 3 persons, 541.2ms\n",
      "Speed: 2.0ms preprocess, 541.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (19).jpg: 480x640 3 persons, 529.7ms\n",
      "Speed: 2.0ms preprocess, 529.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (2).jpg: 480x640 2 persons, 544.8ms\n",
      "Speed: 1.9ms preprocess, 544.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (20).jpg: 480x640 3 persons, 590.7ms\n",
      "Speed: 2.1ms preprocess, 590.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (21).jpg: 480x640 3 persons, 555.1ms\n",
      "Speed: 2.0ms preprocess, 555.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (22).jpg: 480x640 3 persons, 533.4ms\n",
      "Speed: 2.0ms preprocess, 533.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (23).jpg: 480x640 3 persons, 582.1ms\n",
      "Speed: 3.0ms preprocess, 582.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (24).jpg: 480x640 3 persons, 529.9ms\n",
      "Speed: 2.0ms preprocess, 529.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (25).jpg: 480x640 3 persons, 580.0ms\n",
      "Speed: 1.0ms preprocess, 580.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (26).jpg: 480x640 3 persons, 543.0ms\n",
      "Speed: 2.0ms preprocess, 543.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (27).jpg: 480x640 5 persons, 558.2ms\n",
      "Speed: 2.0ms preprocess, 558.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (3).jpg: 480x640 2 persons, 590.1ms\n",
      "Speed: 2.0ms preprocess, 590.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (4).jpg: 480x640 2 persons, 568.1ms\n",
      "Speed: 3.0ms preprocess, 568.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (5).jpg: 480x640 2 persons, 549.1ms\n",
      "Speed: 2.0ms preprocess, 549.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (6).jpg: 480x640 2 persons, 548.6ms\n",
      "Speed: 3.0ms preprocess, 548.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (7).jpg: 480x640 3 persons, 557.7ms\n",
      "Speed: 2.0ms preprocess, 557.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (8).jpg: 480x640 3 persons, 612.5ms\n",
      "Speed: 2.0ms preprocess, 612.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "\n",
      "image 1/1 D:\\AXON\\CCTV\\workspace\\prepare_data\\datasets\\train\\images\\4-1-3_phone_ (9).jpg: 480x640 3 persons, 567.1ms\n",
      "Speed: 2.0ms preprocess, 567.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for file_name in df[df['video_num']=='4-1-3']['file_path'].tolist():\n",
    "    # print(os.path.join(\"datasets\",\"train\",\"images\",file_name+\".jpg\"))\n",
    "    model.predict(os.path.join(\"datasets\",\"train\",\"images\",file_name+\".jpg\"),  conf=0.7, save=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# photo_path_arr = os.listdir('datasets/4-1-3/test/images')\n",
    "# for file_name in photo_path_arr:\n",
    "\n",
    "#     model.predict(os.path.join(\"datasets\",\"4-1-3\",\"test\",\"images\",file_name),  conf=0.65, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"datasets\",\"train\",\"iamges\",'x'+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
